{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ex5] 네이버 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt            # 앞서 konlpy 다운 받기!!! + Mecab도\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터로더 구성\n",
    "+ 데이터의 중복 제거\n",
    "+ NaN 결측치 제거\n",
    "+ 한국어 토크나이저로 토큰화\n",
    "+ 불용어(Stopwords) 제거\n",
    "+ 사전word_to_index 구성\n",
    "+ 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "+ X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # 중복 되는 단어 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist): #사전word_to_index 구성\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word 생성\n",
    "# 텍스트 데이터 -> 숫자로 바꾸기 // 딕셔너리가 {텍스트:인덱스} 구조여야 한다.\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성을 위한 데이터 분석 및 가공\n",
    "+ 데이터셋 내 문장 길이 분포\n",
    "+ 적절한 최대 문장 길이 지정\n",
    "+ keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "#데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "#적절한 최대 문장 길이 지정\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "#keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성 및 validation set 구성(3가지 모델)\n",
    "+ 1) LSTM\n",
    "+ 2) 1-D Convolution Neural Network(1-D CNN)\n",
    "+ 3) GlobalMaxPooling1D() \n",
    "+ 4) 한글 Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) LSTM 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 41)\n",
      "(30000,)\n",
      "(116182, 41)\n",
      "(116182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 30000건 분리     적절한 validataion 데이터는 몇개가 좋을까?\n",
    "x_val = X_train[:30000]   \n",
    "y_val = y_train[:30000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_x_train = X_train[30000:]  \n",
    "partial_y_train = y_train[30000:]\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 3488      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,003,569\n",
      "Trainable params: 1,003,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기입니다.\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "lstm_model = keras.Sequential(name=\"LSTM\")\n",
    "lstm_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm_model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "lstm_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 5s 20ms/step - loss: 0.4676 - accuracy: 0.8001 - val_loss: 0.3562 - val_accuracy: 0.8476\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.3310 - accuracy: 0.8608 - val_loss: 0.3455 - val_accuracy: 0.8496\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.3042 - accuracy: 0.8725 - val_loss: 0.3441 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2866 - accuracy: 0.8803 - val_loss: 0.3477 - val_accuracy: 0.8520\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.2716 - accuracy: 0.8869 - val_loss: 0.3579 - val_accuracy: 0.8512\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.2570 - accuracy: 0.8937 - val_loss: 0.3669 - val_accuracy: 0.8485\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2440 - accuracy: 0.8996 - val_loss: 0.3766 - val_accuracy: 0.8487\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2315 - accuracy: 0.9053 - val_loss: 0.3895 - val_accuracy: 0.8487\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.2203 - accuracy: 0.9113 - val_loss: 0.3978 - val_accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2098 - accuracy: 0.9160 - val_loss: 0.4162 - val_accuracy: 0.8468\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1994 - accuracy: 0.9205 - val_loss: 0.4267 - val_accuracy: 0.8442\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1902 - accuracy: 0.9256 - val_loss: 0.4414 - val_accuracy: 0.8415\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1809 - accuracy: 0.9299 - val_loss: 0.4500 - val_accuracy: 0.8413\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1727 - accuracy: 0.9337 - val_loss: 0.4634 - val_accuracy: 0.8409\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1636 - accuracy: 0.9383 - val_loss: 0.4823 - val_accuracy: 0.8391\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.1538 - accuracy: 0.9434 - val_loss: 0.4963 - val_accuracy: 0.8385\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1460 - accuracy: 0.9471 - val_loss: 0.5144 - val_accuracy: 0.8362\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1404 - accuracy: 0.9493 - val_loss: 0.5251 - val_accuracy: 0.8369\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1354 - accuracy: 0.9517 - val_loss: 0.5503 - val_accuracy: 0.8368\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1288 - accuracy: 0.9550 - val_loss: 0.5476 - val_accuracy: 0.8346\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "lstm_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = lstm_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 6s - loss: 0.5582 - accuracy: 0.8300\n",
      "[0.5581883788108826, 0.8299530148506165]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "lstm_results = lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(lstm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 1-D Convolution Neural Network(1-D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 16)          11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기\n",
    "word_vector_dim = 100       # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.4701 - accuracy: 0.7694 - val_loss: 0.3440 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.3118 - accuracy: 0.8682 - val_loss: 0.3282 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.2606 - accuracy: 0.8940 - val_loss: 0.3334 - val_accuracy: 0.8569\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.2082 - accuracy: 0.9203 - val_loss: 0.3508 - val_accuracy: 0.8540\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.1492 - accuracy: 0.9470 - val_loss: 0.3902 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1016 - accuracy: 0.9668 - val_loss: 0.4519 - val_accuracy: 0.8470\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0703 - accuracy: 0.9777 - val_loss: 0.5372 - val_accuracy: 0.8424\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.5881 - val_accuracy: 0.8414\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.6444 - val_accuracy: 0.8404\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.7218 - val_accuracy: 0.8366\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.7649 - val_accuracy: 0.8379\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 5s 21ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.8101 - val_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.8484 - val_accuracy: 0.8335\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.8901 - val_accuracy: 0.8325\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.9533 - val_accuracy: 0.8334\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.9983 - val_accuracy: 0.8309\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 1.0340 - val_accuracy: 0.8293\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.9589 - val_accuracy: 0.8302\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.9970 - val_accuracy: 0.8286\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 1.0672 - val_accuracy: 0.8307\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "CNN_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = CNN_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 1.1065 - accuracy: 0.8240\n",
      "[1.1065272092819214, 0.8239518404006958]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "CNN_results = CNN_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(CNN_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)GlobalMaxPooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GlabalMaxPooling1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,000,817\n",
      "Trainable params: 1,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기\n",
    "word_vector_dim = 100       # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "MaxPooling1D_model = keras.Sequential(name=\"GlabalMaxPooling1D\")\n",
    "MaxPooling1D_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "MaxPooling1D_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "MaxPooling1D_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "MaxPooling1D_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "MaxPooling1D_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 0.4999 - accuracy: 0.7925 - val_loss: 0.3603 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.3271 - accuracy: 0.8612 - val_loss: 0.3379 - val_accuracy: 0.8524\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 0.2813 - accuracy: 0.8846 - val_loss: 0.3376 - val_accuracy: 0.8539\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.2465 - accuracy: 0.9027 - val_loss: 0.3466 - val_accuracy: 0.8544\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.2142 - accuracy: 0.9181 - val_loss: 0.3637 - val_accuracy: 0.8518\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.1832 - accuracy: 0.9323 - val_loss: 0.3838 - val_accuracy: 0.8513\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.1524 - accuracy: 0.9469 - val_loss: 0.4093 - val_accuracy: 0.8499\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.1229 - accuracy: 0.9602 - val_loss: 0.4444 - val_accuracy: 0.8467\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 0.0969 - accuracy: 0.9704 - val_loss: 0.4812 - val_accuracy: 0.8440\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0749 - accuracy: 0.9790 - val_loss: 0.5257 - val_accuracy: 0.8409\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0580 - accuracy: 0.9848 - val_loss: 0.5606 - val_accuracy: 0.8388\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0449 - accuracy: 0.9886 - val_loss: 0.6022 - val_accuracy: 0.8385\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0347 - accuracy: 0.9918 - val_loss: 0.6461 - val_accuracy: 0.8355\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.6772 - val_accuracy: 0.8342\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.7106 - val_accuracy: 0.8346\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.7408 - val_accuracy: 0.8327\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.7740 - val_accuracy: 0.8321\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.7972 - val_accuracy: 0.8324\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.8263 - val_accuracy: 0.8313\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.8453 - val_accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "MaxPooling1D_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을까?\n",
    "\n",
    "history = MaxPooling1D_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.8568 - accuracy: 0.8294\n",
      "[0.8567613363265991, 0.8293834328651428]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "MaxPooling1D_results = MaxPooling1D_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(MaxPooling1D_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모두 같은 조건을 가지고 모델 학습을 하여 테스트셋으로 평가하였다.\n",
    "```\n",
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기\n",
    "word_vector_dim = 100       # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM 모델의 성능\n",
      "1537/1537 - 7s - loss: 0.5582 - accuracy: 0.8300\n",
      "CNN 모델의 성능\n",
      "1537/1537 - 4s - loss: 1.1065 - accuracy: 0.8240\n",
      "MaxPooling1D 모델의 성능\n",
      "1537/1537 - 2s - loss: 0.8568 - accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM 모델의 성능\")\n",
    "lstm_results = lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(\"CNN 모델의 성능\")\n",
    "CNN_results = CNN_model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(\"MaxPooling1D 모델의 성능\")\n",
    "MaxPooling1D_results = MaxPooling1D_model.evaluate(X_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델의 accuracy를 비교하였을 때, **LSTM**의 성능이 가장 높았으며, 판단하였으며 이를 이후 학습 모델로 선정하여 성능 개선을 할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 1000)        10000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                132224    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 10,132,497\n",
      "Trainable params: 10,132,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기입니다.\n",
    "word_vector_dim = 1000  # 단어 하나를 표현하는 임베딩 벡터의 차원수(변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "lstm2_model = keras.Sequential(name=\"LSTM2\")\n",
    "lstm2_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm2_model.add(keras.layers.LSTM(32))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 변경가능\n",
    "lstm2_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm2_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "lstm2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 오버피팅 없애기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "     #validataion set의 loss를 monitoring 한다\n",
    "     #performance measuer(어떤 성능을 모니터링 할것인가?) 를 최소화 시켜야하는 training이다.\n",
    "     #verbose=1 : 언제 keras에서 training을 멈추었는지 화면에 출력\n",
    "     #patience : 성능이 더이상 증가하지 않은 epoch를 몇 번이나 허용할 것인가?\n",
    "    \n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    " #EarlyStopping 객체에 의해 training이 중지되었을 때, validation performance가 가장 높았던 모델 선정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "454/454 [==============================] - 57s 126ms/step - loss: 0.3902 - accuracy: 0.8261 - val_loss: 0.3356 - val_accuracy: 0.8548\n",
      "Epoch 2/20\n",
      "454/454 [==============================] - 57s 125ms/step - loss: 0.2949 - accuracy: 0.8749 - val_loss: 0.3301 - val_accuracy: 0.8588\n",
      "Epoch 3/20\n",
      "454/454 [==============================] - 55s 122ms/step - loss: 0.2487 - accuracy: 0.8964 - val_loss: 0.3370 - val_accuracy: 0.8606\n",
      "Epoch 4/20\n",
      "454/454 [==============================] - 60s 131ms/step - loss: 0.2061 - accuracy: 0.9163 - val_loss: 0.3643 - val_accuracy: 0.8578\n",
      "Epoch 5/20\n",
      "454/454 [==============================] - 59s 130ms/step - loss: 0.1690 - accuracy: 0.9344 - val_loss: 0.3855 - val_accuracy: 0.8563\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "lstm2_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = lstm2_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[es,mc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 6s - loss: 0.3895 - accuracy: 0.8531\n",
      "[0.38945603370666504, 0.8530829548835754]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "lstm2_results = lstm2_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(lstm2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Accuracy 그래프 시각화  \n",
    "- model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있다.\n",
    "- 이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, 성능을 개선할 수 있는 방안을 알 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and validation accuracy 그리기\n",
    "plt.clf()   # 그림을 초기화\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 벡터 차원수 -> 100 - accuracy : 0.8300  \n",
    "       -> 500 - accuracy: 0.8412 (오버피팅 발생)  \n",
    "       -> 500 - accuracy : 0.8496 (dropout/earlystopping 진행 했으나 정확도를 더 높여야 한다.) \n",
    "       -> 1000 - accuracy : 0.8531 (bach size 줄이고, 워드 벡터 차원수를 늘인 만큼 LSTM state 벡터의 차원수도 높였다.)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = lstm2_model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
