{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ex5] 네이버 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt            # 앞서 konlpy 다운 받기!!! + Mecab도\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터로더 구성\n",
    "+ 데이터의 중복 제거\n",
    "+ NaN 결측치 제거\n",
    "+ 한국어 토크나이저로 토큰화\n",
    "+ 불용어(Stopwords) 제거\n",
    "+ 사전word_to_index 구성\n",
    "+ 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "+ X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    # 중복 되는 단어 제거\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist): #사전word_to_index 구성\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_to_word 생성\n",
    "# 텍스트 데이터 -> 숫자로 바꾸기 // 딕셔너리가 {텍스트:인덱스} 구조여야 한다.\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성을 위한 데이터 분석 및 가공\n",
    "+ 데이터셋 내 문장 길이 분포\n",
    "+ 적절한 최대 문장 길이 지정\n",
    "+ keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "#데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "#적절한 최대 문장 길이 지정\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "#keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구성 및 validation set 구성(3가지 모델)\n",
    "+ 1) LSTM\n",
    "+ 2) 1-D Convolution Neural Network(1-D CNN)\n",
    "+ 3) GlobalMaxPooling1D() \n",
    "+ 4) 한글 Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) LSTM 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 41)\n",
      "(30000,)\n",
      "(116182, 41)\n",
      "(116182,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 30000건 분리     적절한 validataion 데이터는 몇개가 좋을까?\n",
    "x_val = X_train[:30000]   \n",
    "y_val = y_train[:30000]\n",
    "\n",
    "# validation set을 제외한 나머지 \n",
    "partial_x_train = X_train[30000:]  \n",
    "partial_y_train = y_train[30000:]\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 3488      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,003,569\n",
      "Trainable params: 1,003,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기입니다.\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "lstm_model = keras.Sequential(name=\"LSTM\")\n",
    "lstm_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm_model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "lstm_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 5s 20ms/step - loss: 0.4676 - accuracy: 0.8001 - val_loss: 0.3562 - val_accuracy: 0.8476\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.3310 - accuracy: 0.8608 - val_loss: 0.3455 - val_accuracy: 0.8496\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.3042 - accuracy: 0.8725 - val_loss: 0.3441 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2866 - accuracy: 0.8803 - val_loss: 0.3477 - val_accuracy: 0.8520\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.2716 - accuracy: 0.8869 - val_loss: 0.3579 - val_accuracy: 0.8512\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.2570 - accuracy: 0.8937 - val_loss: 0.3669 - val_accuracy: 0.8485\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2440 - accuracy: 0.8996 - val_loss: 0.3766 - val_accuracy: 0.8487\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2315 - accuracy: 0.9053 - val_loss: 0.3895 - val_accuracy: 0.8487\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.2203 - accuracy: 0.9113 - val_loss: 0.3978 - val_accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.2098 - accuracy: 0.9160 - val_loss: 0.4162 - val_accuracy: 0.8468\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1994 - accuracy: 0.9205 - val_loss: 0.4267 - val_accuracy: 0.8442\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1902 - accuracy: 0.9256 - val_loss: 0.4414 - val_accuracy: 0.8415\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1809 - accuracy: 0.9299 - val_loss: 0.4500 - val_accuracy: 0.8413\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1727 - accuracy: 0.9337 - val_loss: 0.4634 - val_accuracy: 0.8409\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1636 - accuracy: 0.9383 - val_loss: 0.4823 - val_accuracy: 0.8391\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.1538 - accuracy: 0.9434 - val_loss: 0.4963 - val_accuracy: 0.8385\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1460 - accuracy: 0.9471 - val_loss: 0.5144 - val_accuracy: 0.8362\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1404 - accuracy: 0.9493 - val_loss: 0.5251 - val_accuracy: 0.8369\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1354 - accuracy: 0.9517 - val_loss: 0.5503 - val_accuracy: 0.8368\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1288 - accuracy: 0.9550 - val_loss: 0.5476 - val_accuracy: 0.8346\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "lstm_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = lstm_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 6s - loss: 0.5582 - accuracy: 0.8300\n",
      "[0.5581883788108826, 0.8299530148506165]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "lstm_results = lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(lstm_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 1-D Convolution Neural Network(1-D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 16)          11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,013,169\n",
      "Trainable params: 1,013,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기\n",
    "word_vector_dim = 100       # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "CNN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.4701 - accuracy: 0.7694 - val_loss: 0.3440 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.3118 - accuracy: 0.8682 - val_loss: 0.3282 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.2606 - accuracy: 0.8940 - val_loss: 0.3334 - val_accuracy: 0.8569\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.2082 - accuracy: 0.9203 - val_loss: 0.3508 - val_accuracy: 0.8540\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.1492 - accuracy: 0.9470 - val_loss: 0.3902 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.1016 - accuracy: 0.9668 - val_loss: 0.4519 - val_accuracy: 0.8470\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0703 - accuracy: 0.9777 - val_loss: 0.5372 - val_accuracy: 0.8424\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.5881 - val_accuracy: 0.8414\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.6444 - val_accuracy: 0.8404\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.7218 - val_accuracy: 0.8366\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 4s 18ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.7649 - val_accuracy: 0.8379\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 5s 21ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.8101 - val_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.8484 - val_accuracy: 0.8335\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.8901 - val_accuracy: 0.8325\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.9533 - val_accuracy: 0.8334\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.9983 - val_accuracy: 0.8309\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0205 - accuracy: 0.9926 - val_loss: 1.0340 - val_accuracy: 0.8293\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0305 - accuracy: 0.9890 - val_loss: 0.9589 - val_accuracy: 0.8302\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 4s 17ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.9970 - val_accuracy: 0.8286\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 1.0672 - val_accuracy: 0.8307\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "CNN_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = CNN_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 4s - loss: 1.1065 - accuracy: 0.8240\n",
      "[1.1065272092819214, 0.8239518404006958]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "CNN_results = CNN_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(CNN_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)GlobalMaxPooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GlabalMaxPooling1D\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,000,817\n",
      "Trainable params: 1,000,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기\n",
    "word_vector_dim = 100       # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "\n",
    "MaxPooling1D_model = keras.Sequential(name=\"GlabalMaxPooling1D\")\n",
    "MaxPooling1D_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "MaxPooling1D_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "MaxPooling1D_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "MaxPooling1D_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "MaxPooling1D_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 0.4999 - accuracy: 0.7925 - val_loss: 0.3603 - val_accuracy: 0.8420\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.3271 - accuracy: 0.8612 - val_loss: 0.3379 - val_accuracy: 0.8524\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 0.2813 - accuracy: 0.8846 - val_loss: 0.3376 - val_accuracy: 0.8539\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.2465 - accuracy: 0.9027 - val_loss: 0.3466 - val_accuracy: 0.8544\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.2142 - accuracy: 0.9181 - val_loss: 0.3637 - val_accuracy: 0.8518\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.1832 - accuracy: 0.9323 - val_loss: 0.3838 - val_accuracy: 0.8513\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.1524 - accuracy: 0.9469 - val_loss: 0.4093 - val_accuracy: 0.8499\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.1229 - accuracy: 0.9602 - val_loss: 0.4444 - val_accuracy: 0.8467\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 4s 15ms/step - loss: 0.0969 - accuracy: 0.9704 - val_loss: 0.4812 - val_accuracy: 0.8440\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0749 - accuracy: 0.9790 - val_loss: 0.5257 - val_accuracy: 0.8409\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0580 - accuracy: 0.9848 - val_loss: 0.5606 - val_accuracy: 0.8388\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0449 - accuracy: 0.9886 - val_loss: 0.6022 - val_accuracy: 0.8385\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0347 - accuracy: 0.9918 - val_loss: 0.6461 - val_accuracy: 0.8355\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.6772 - val_accuracy: 0.8342\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.7106 - val_accuracy: 0.8346\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 4s 19ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.7408 - val_accuracy: 0.8327\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.7740 - val_accuracy: 0.8321\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.7972 - val_accuracy: 0.8324\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.8263 - val_accuracy: 0.8313\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 4s 16ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.8453 - val_accuracy: 0.8324\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "MaxPooling1D_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을까?\n",
    "\n",
    "history = MaxPooling1D_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 2s - loss: 0.8568 - accuracy: 0.8294\n",
      "[0.8567613363265991, 0.8293834328651428]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "MaxPooling1D_results = MaxPooling1D_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(MaxPooling1D_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모두 같은 조건을 가지고 모델 학습을 하여 테스트셋으로 평가하였다.\n",
    "```\n",
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기\n",
    "word_vector_dim = 100       # 단어 하나를 표현하는 임베딩 벡터의 차원수\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM 모델의 성능\n",
      "1537/1537 - 7s - loss: 0.5582 - accuracy: 0.8300\n",
      "CNN 모델의 성능\n",
      "1537/1537 - 4s - loss: 1.1065 - accuracy: 0.8240\n",
      "MaxPooling1D 모델의 성능\n",
      "1537/1537 - 2s - loss: 0.8568 - accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM 모델의 성능\")\n",
    "lstm_results = lstm_model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(\"CNN 모델의 성능\")\n",
    "CNN_results = CNN_model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(\"MaxPooling1D 모델의 성능\")\n",
    "MaxPooling1D_results = MaxPooling1D_model.evaluate(X_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모델의 accuracy를 비교하였을 때, **LSTM**의 성능이 가장 높았으며, 판단하였으며 이를 이후 학습 모델로 선정하여 성능 개선을 할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 500)         5000000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 8)                 16288     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 5,016,369\n",
      "Trainable params: 5,016,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)   # 어휘 사전의 크기입니다.\n",
    "word_vector_dim = 500  # 단어 하나를 표현하는 임베딩 벡터의 차원수(변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "lstm2_model = keras.Sequential(name=\"LSTM2\")\n",
    "lstm2_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm2_model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 변경가능\n",
    "\n",
    "lstm2_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm2_model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "lstm2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버피팅 없애기\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "    # validataion set의 loss를 monitoring 한다\n",
    "    # performance measuer(어떤 성능을 모니터링 할것인가?) 를 최소화 시켜야하는 training이다.\n",
    "    # verbose=1 : 언제 keras에서 training을 멈추었는지 화면에 출력\n",
    "    # patience : 성능이 더이상 증가하지 않은 epoch를 몇 번이나 허용할 것인가?\n",
    "    \n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# EarlyStopping 객체에 의해 training이 중지되었을 때, validation performance가 가장 높았던 모델 선정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 0.4534 - accuracy: 0.8007 - val_loss: 0.3538 - val_accuracy: 0.8488\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 0.3233 - accuracy: 0.8644 - val_loss: 0.3359 - val_accuracy: 0.8543\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 24s 108ms/step - loss: 0.2843 - accuracy: 0.8830 - val_loss: 0.3362 - val_accuracy: 0.8556\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 24s 107ms/step - loss: 0.2526 - accuracy: 0.8969 - val_loss: 0.3483 - val_accuracy: 0.8545\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 25s 109ms/step - loss: 0.2235 - accuracy: 0.9107 - val_loss: 0.3586 - val_accuracy: 0.8540\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 시작\n",
    "lstm2_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = lstm2_model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 11s - loss: 0.3684 - accuracy: 0.8496\n",
      "[0.36835530400276184, 0.8495839834213257]\n"
     ]
    }
   ],
   "source": [
    "# 학습 끝난 모델을 테스트셋으로 평가하기\n",
    "lstm2_results = lstm2_model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(lstm2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss, Accuracy 그래프 시각화  \n",
    "- model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있다.\n",
    "- 이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, 성능을 개선할 수 있는 방안을 알 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and validation accuracy 그리기\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 벡터 차원수 -> 100 - accuracy : 0.8300\n",
    "                -> 500 - accuracy: 0.8412 (오버피팅 발생)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
