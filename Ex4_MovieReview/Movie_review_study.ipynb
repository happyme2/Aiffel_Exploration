{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터의 특징  \n",
    "### (1) 텍스트를 숫자로 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "#텍스트 데이터 -> 사전 만들기 \n",
    "#문장을 단어 단위로 쪼개고, 파이썬 dict 자료구조로 표현\n",
    "\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "#텍스트 데이터 -> 숫자로 바꾸기 // 딕셔너리가 {텍스트:인덱스} 구조여야 한다. \n",
    "\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#딕셔너리 - 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용 가능하다.\n",
    "\n",
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트 데이터를 숫자로 바꿔 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))   #get_encoded_sentence 함수 이용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 반대로, encode된 벡터를 decode하여 다시 원래 텍스트 데이터로 복구\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Embedding 레이어의 등장  \n",
    "+ 숫자로만 변환했지 의미와 짝지어지지는 않았다.\n",
    "+ 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 딥러닝을 통하여 학습에 최적화.\n",
    "Tensorflow, Pytorch 딥러닝 프레임쿼크들은 의미벡터 파라미터를 구현한 Embedding 레이어를 제공한다."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-33b6467d835f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_non_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;31m# `SparseTensors` can't be converted to `Tensor`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import warnings  ### numpy 버전 때문에 발생하는 오류 멈추기\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 한다.  \n",
    "raw_inputs의 3개 벡터의 길이는 각각 4, 4, 5 이다.  \n",
    "  \n",
    "+ Tensorflow에서는 **keras.preprocessing.sequence.pad_sequences**라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "\n",
    "print(raw_inputs)   #짧은 문장에는 0으로 채워진다. <PAD>가 0에 맵핑되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.03328012  0.00962071  0.03160839  0.048016  ]\n",
      "  [ 0.01901842 -0.02278158  0.01250697 -0.02378705]\n",
      "  [-0.04871898  0.01841608  0.03458837  0.01635096]\n",
      "  [-0.01078454  0.02021327 -0.03762134 -0.02432919]\n",
      "  [-0.03572606 -0.04465016 -0.04217388  0.0286038 ]]\n",
      "\n",
      " [[-0.03328012  0.00962071  0.03160839  0.048016  ]\n",
      "  [ 0.01901842 -0.02278158  0.01250697 -0.02378705]\n",
      "  [-0.03875094 -0.03583684 -0.03724943  0.01365019]\n",
      "  [-0.04923239 -0.00955736 -0.04452666 -0.0132686 ]\n",
      "  [-0.03572606 -0.04465016 -0.04217388  0.0286038 ]]\n",
      "\n",
      " [[-0.03328012  0.00962071  0.03160839  0.048016  ]\n",
      "  [-0.02287952 -0.0482345  -0.01309503  0.04071685]\n",
      "  [ 0.01901842 -0.02278158  0.01250697 -0.02378705]\n",
      "  [-0.04871898  0.01841608  0.03458837  0.01635096]\n",
      "  [-0.04166108 -0.03547651 -0.03381287  0.04848771]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#  output = embedding(raw_inputs) 다시 시도\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings  ### numpy 버전 때문에 발생하는 오류 멈추기\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output의 shape=(3, 5, 4)에서 3, 5, 4의 의미  \n",
    ": 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드벡터의 차원수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시퀀스 데이터를 다루는 RNN  \n",
    "+ 텍스트 데이터 주로 사용하는 딥러닝 모델은 **RNN**  \n",
    "+ RNN은 시간 흐름에 따라 새로운 입력으로 변하는 현재 상태를 묘사하는 **state machine** 으로 설계 되어 있다   \n",
    "\n",
    "   + **Sequence data** - 입력이 시간축을 따라 발생하는 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM 모델\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 대신 1-D Convolution Neural Network(1-D CNN)을 사용\n",
    "+ 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝 하여 7단어이내에서 발견되는 특징을 추출하고, 그것으로 문장을 분류  \n",
    "+ CNN은 RNN보다 병렬처리가 효율적 / 학습속도도 훨씬 빠르다\n",
    "\n",
    "이미지 분류기는 이미지 전체가 한꺼번에 입력 되어 2-D CNN 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalMaxPooling1D() 레이어 하나만 사용\n",
    "+ 전체 문장 중 중요한 단어 하나를 추출해서 그 하나로 문장의 긍정/부정을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 해볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 영화리뷰 감성분석   \n",
    "## (1) IMDB 데이터셋 분석\n",
    "+  IMDB Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성\n",
    "+ 25000개가 훈련용 데이터, 나머지 25000개를 테스트용 데이터로 사용하도록 지정\n",
    "+ 긍정은 1, 부정은 0의 라벨\n",
    "+ tensorflow Keras 데이터셋 안에 포함되어 있어서 손쉽게 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import warnings  ### numpy 버전 때문에 발생하는 오류 멈추기\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "# imdb.load_data() 호출시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면\n",
    "# 그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성\n",
    "\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))  # 이미 숫자로 encode된 텍스트 데이터\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "#word_to_index는 IMDB 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 다운 받은 데이터셋 확인 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# encode된 텍스트가 정상적으로 decode 되었는가?\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ pad_sequences - 문장의 길이 통일 하는것 잊지 말자!!\n",
    "+ 문장 최대 길이 maxlen - 전체 모델 성능에 영향/적절한 값(전체 데이터셋 분포 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **padding 방식을 문장 뒷쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 딥러닝 모델 설계와 훈련  \n",
    "#### RNN 모델 직접 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리     적절한 validataion 데이터는 몇개가 좋을까?\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 112ms/step - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6932 - val_accuracy: 0.5004\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.6929 - accuracy: 0.5157 - val_loss: 0.6931 - val_accuracy: 0.5034\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 92ms/step - loss: 0.6923 - accuracy: 0.5221 - val_loss: 0.6930 - val_accuracy: 0.5023\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 92ms/step - loss: 0.6907 - accuracy: 0.5157 - val_loss: 0.6924 - val_accuracy: 0.5033\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.6861 - accuracy: 0.5224 - val_loss: 0.6903 - val_accuracy: 0.5106\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.6781 - accuracy: 0.5243 - val_loss: 0.6893 - val_accuracy: 0.5122\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.6711 - accuracy: 0.5333 - val_loss: 0.6932 - val_accuracy: 0.5082\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.6649 - accuracy: 0.5322 - val_loss: 0.6921 - val_accuracy: 0.5093\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.6607 - accuracy: 0.5366 - val_loss: 0.6903 - val_accuracy: 0.5111\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 91ms/step - loss: 0.6569 - accuracy: 0.5323 - val_loss: 0.6959 - val_accuracy: 0.5130\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.6526 - accuracy: 0.5395 - val_loss: 0.6952 - val_accuracy: 0.5384\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 108ms/step - loss: 0.9429 - accuracy: 0.5593 - val_loss: 0.7033 - val_accuracy: 0.5148\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.6584 - accuracy: 0.5271 - val_loss: 0.6911 - val_accuracy: 0.5100\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 92ms/step - loss: 0.6563 - accuracy: 0.5368 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.6550 - accuracy: 0.5371 - val_loss: 0.6930 - val_accuracy: 0.5105\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.6542 - accuracy: 0.5374 - val_loss: 0.6933 - val_accuracy: 0.5105\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.6533 - accuracy: 0.5300 - val_loss: 0.6937 - val_accuracy: 0.5133\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 93ms/step - loss: 0.6526 - accuracy: 0.5385 - val_loss: 0.6947 - val_accuracy: 0.5113\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.6518 - accuracy: 0.5383 - val_loss: 0.6950 - val_accuracy: 0.5120\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.6509 - accuracy: 0.5386 - val_loss: 0.6953 - val_accuracy: 0.5130\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 끝난 모델을 테스트셋으로 평가하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 12s - loss: 0.6076 - accuracy: 0.6909\n",
      "[0.6076225638389587, 0.6909199953079224]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있다.\n",
    "+ 이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지, 성능을 개선할 수 있는 다양한 아이디어를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정\n",
    "+ validation loss의 그래프가 train loss와의 이격이 발생하게 되면 더이상의 트레이닝은 무의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and validation accuracy 그리기\n",
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **워드 임베딩(word embedding) 기법** \n",
    "  - 사전 단어의 갯수 * 워드 벡터 사이즈 만큼의 크기를 가진 학습 파라미터  \n",
    "\n",
    "1) 워드 벡터 파일 저장할 디렉토리 생성  \n",
    "2) 워드 벡터를 다루는데 유용한 gensim 패키지 설치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06880355,  0.0135476 , -0.01405306, -0.07444121, -0.07870492,\n",
       "        0.07162485,  0.08512371, -0.08819003, -0.06710541,  0.10623881,\n",
       "        0.04169302, -0.0217862 ,  0.02280826, -0.02360039, -0.06963111,\n",
       "        0.00805563], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pleasant', 0.9068766832351685),\n",
       " ('flick', 0.9057583212852478),\n",
       " ('guide', 0.9028802514076233),\n",
       " ('freedom', 0.9007776379585266),\n",
       " ('1939', 0.8947765231132507),\n",
       " ('she', 0.8904246091842651),\n",
       " ('texas', 0.8853615522384644),\n",
       " ('musicals', 0.885327935218811),\n",
       " ('goers', 0.8847764730453491),\n",
       " ('wrap', 0.8847330212593079)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 워드 벡터가 의미벡터 공간상에 유의미하게 학습되었는지 확인\n",
    "word_vectors.similar_by_word(\"love\")\n",
    "# 학습 잘 되었는지 모르겠음 -> 구글 제공 Word2Vec 워드임베딩 모델 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구글 제공 Word2Vec 워드임베딩 모델 이용  \n",
    "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)  #상위 100만개만.. 아니면 limit=None\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907792091369629),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100709438323975),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547305345535278),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이전 스텝에서 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 다시 학습\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 23s 768ms/step - loss: 0.6950 - accuracy: 0.5149 - val_loss: 0.6885 - val_accuracy: 0.5481\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 10s 348ms/step - loss: 0.6760 - accuracy: 0.5909 - val_loss: 0.6771 - val_accuracy: 0.5667\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 11s 351ms/step - loss: 0.6195 - accuracy: 0.6768 - val_loss: 0.5769 - val_accuracy: 0.7052\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 10s 350ms/step - loss: 0.4452 - accuracy: 0.8156 - val_loss: 0.3686 - val_accuracy: 0.8442\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 10s 350ms/step - loss: 0.2946 - accuracy: 0.8821 - val_loss: 0.3173 - val_accuracy: 0.8651\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 0.2111 - accuracy: 0.9255 - val_loss: 0.3039 - val_accuracy: 0.8723\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 0.1645 - accuracy: 0.9451 - val_loss: 0.3080 - val_accuracy: 0.8749\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 10s 339ms/step - loss: 0.1165 - accuracy: 0.9673 - val_loss: 0.3119 - val_accuracy: 0.8756\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 0.0879 - accuracy: 0.9789 - val_loss: 0.3354 - val_accuracy: 0.8717\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 0.0728 - accuracy: 0.9824 - val_loss: 0.3367 - val_accuracy: 0.8738\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 10s 340ms/step - loss: 0.0457 - accuracy: 0.9936 - val_loss: 0.3612 - val_accuracy: 0.8720\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 10s 342ms/step - loss: 0.0326 - accuracy: 0.9972 - val_loss: 0.3690 - val_accuracy: 0.8730\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 10s 340ms/step - loss: 0.0233 - accuracy: 0.9982 - val_loss: 0.3811 - val_accuracy: 0.8743\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 10s 338ms/step - loss: 0.0173 - accuracy: 0.9988 - val_loss: 0.3995 - val_accuracy: 0.8738\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 0.0117 - accuracy: 0.9994 - val_loss: 0.4123 - val_accuracy: 0.8744\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 10s 343ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 0.4293 - val_accuracy: 0.8745\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 10s 339ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.4433 - val_accuracy: 0.8739\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 10s 340ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.4540 - val_accuracy: 0.8727\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 10s 342ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.4675 - val_accuracy: 0.8741\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 10s 341ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.4758 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 11s - loss: 0.5303 - accuracy: 0.8602\n",
      "[0.5303415060043335, 0.8601599931716919]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word2Vec을 정상적으로 잘 활용하면 그렇지 않은 경우보다 5% 이상의 성능향상\n",
    "- 적절한 모델구성, 하이퍼파라미터를 고려하여 감정분석 모델의 성능 높이기!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
