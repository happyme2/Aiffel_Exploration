{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭킹 올리기! \n",
    "## 최적의 모델을 위한 데이터 준비하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt   #  matplotlib 시각화\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료 !\n"
     ]
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "train_data_path = join(data_dir, 'train.csv')\n",
    "test_data_path = join(data_dir, 'test.csv') \n",
    "\n",
    "train = pd.read_csv(train_data_path)\n",
    "test = pd.read_csv(test_data_path)\n",
    "\n",
    "print('완료 !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0   0  20141013T000000  221900.0         3       1.00         1180      5650   \n",
       "1   1  20150225T000000  180000.0         2       1.00          770     10000   \n",
       "2   2  20150218T000000  510000.0         3       2.00         1680      8080   \n",
       "3   3  20140627T000000  257500.0         3       2.25         1715      6819   \n",
       "4   4  20150115T000000  291850.0         3       1.50         1060      9711   \n",
       "\n",
       "   floors  waterfront  view  ...  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0     1.0           0     0  ...      7        1180              0      1955   \n",
       "1     1.0           0     0  ...      6         770              0      1933   \n",
       "2     1.0           0     0  ...      8        1680              0      1987   \n",
       "3     2.0           0     0  ...      7        1715              0      1995   \n",
       "4     1.0           0     0  ...      7        1060              0      1963   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0             0    98178  47.5112 -122.257           1340        5650  \n",
       "1             0    98028  47.7379 -122.233           2720        8062  \n",
       "2             0    98074  47.6168 -122.045           1800        7503  \n",
       "3             0    98003  47.3097 -122.327           2238        6819  \n",
       "4             0    98198  47.4095 -122.315           1650        9711  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 살펴보기\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>201410</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>201502</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>201502</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>201406</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>201501</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0   0  201410  221900.0         3       1.00         1180      5650     1.0   \n",
       "1   1  201502  180000.0         2       1.00          770     10000     1.0   \n",
       "2   2  201502  510000.0         3       2.00         1680      8080     1.0   \n",
       "3   3  201406  257500.0         3       2.25         1715      6819     2.0   \n",
       "4   4  201501  291850.0         3       1.50         1060      9711     1.0   \n",
       "\n",
       "   waterfront  view  ...  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0           0     0  ...      7        1180              0      1955   \n",
       "1           0     0  ...      6         770              0      1933   \n",
       "2           0     0  ...      8        1680              0      1987   \n",
       "3           0     0  ...      7        1715              0      1995   \n",
       "4           0     0  ...      7        1060              0      1963   \n",
       "\n",
       "   yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0             0    98178  47.5112 -122.257           1340        5650  \n",
       "1             0    98028  47.7379 -122.233           2720        8062  \n",
       "2             0    98074  47.6168 -122.045           1800        7503  \n",
       "3             0    98003  47.3097 -122.327           2238        6819  \n",
       "4             0    98198  47.4095 -122.315           1650        9711  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date int형으로 전처리\n",
    "train['date'] = train['date'].apply(lambda i: i[:6]).astype(int)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
      "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
      "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
      "       'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# price 컬럼 전처리 - train에서 삭제\n",
    "y = train['price']\n",
    "del train['price']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
      "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
      "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
      "       'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# id 컬럼까지 삭제\n",
    "del train['id']\n",
    "\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
      "       'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
      "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
      "       'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# test 데이터에도 똑같이~ (date, id)\n",
    "test['date'] = test['date'].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "del test['id']\n",
    "\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         221900.0\n",
       "1         180000.0\n",
       "2         510000.0\n",
       "3         257500.0\n",
       "4         291850.0\n",
       "           ...    \n",
       "15030     610685.0\n",
       "15031    1007500.0\n",
       "15032     360000.0\n",
       "15033     400000.0\n",
       "15034     325000.0\n",
       "Name: price, Length: 15035, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 데이터 y \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seaborn의 `kdeplot`을 활용해 `y`의 분포를 확인 - 가격 데이터 분포\n",
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12.309987\n",
       "1        12.100718\n",
       "2        13.142168\n",
       "3        12.458779\n",
       "4        12.583999\n",
       "           ...    \n",
       "15030    13.322338\n",
       "15031    13.822984\n",
       "15032    12.793862\n",
       "15033    12.899222\n",
       "15034    12.691584\n",
       "Name: price, Length: 15035, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y 로그 변환 -> 정규화 그래프\n",
    "y = np.log1p(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15035 entries, 0 to 15034\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           15035 non-null  int64  \n",
      " 1   bedrooms       15035 non-null  int64  \n",
      " 2   bathrooms      15035 non-null  float64\n",
      " 3   sqft_living    15035 non-null  int64  \n",
      " 4   sqft_lot       15035 non-null  int64  \n",
      " 5   floors         15035 non-null  float64\n",
      " 6   waterfront     15035 non-null  int64  \n",
      " 7   view           15035 non-null  int64  \n",
      " 8   condition      15035 non-null  int64  \n",
      " 9   grade          15035 non-null  int64  \n",
      " 10  sqft_above     15035 non-null  int64  \n",
      " 11  sqft_basement  15035 non-null  int64  \n",
      " 12  yr_built       15035 non-null  int64  \n",
      " 13  yr_renovated   15035 non-null  int64  \n",
      " 14  zipcode        15035 non-null  int64  \n",
      " 15  lat            15035 non-null  float64\n",
      " 16  long           15035 non-null  float64\n",
      " 17  sqft_living15  15035 non-null  int64  \n",
      " 18  sqft_lot15     15035 non-null  int64  \n",
      "dtypes: float64(4), int64(15)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# info() 함수로 전체 데이터 자료형 확인 - 실수/정수이다.\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 튜닝\n",
    "- XGBoosting\n",
    "- LightGBM\n",
    "- Gradient Boosting\n",
    "- Random Forest  \n",
    "\n",
    "### RMSE 계산 - 평균 제곱근 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라이브러리 불러오기!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  # 데이터셋을 훈련 데이터셋과 검증 데이터셋으로 나누기 위해\n",
    "from sklearn.metrics import mean_squared_error # RMSE 점수를 계산하기 위해\n",
    "\n",
    "print('라이브러리 불러오기!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 값 준비 완료!\n"
     ]
    }
   ],
   "source": [
    "# y_test, y_pred는 위에서 np.log1p()로 변환 된 값 \n",
    "# 원래 데이터의 단위에 맞게 되돌리기 위해 np.expm1() 추가\n",
    "# exp로 다시 변환해서 mean_squared_error를 계산한 값에 np.sqrt를 취하기 (RMSE 값)\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))\n",
    "\n",
    "print('RMSE 값 준비 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 불러오기 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기 (XGBRegressor, LGBMRegressor, GradientBoostingRegressor, RandomForestRegressor)\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "print('모델 불러오기 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**random_state**  \n",
    "- 1) **특정 값 고정** : 모델과 데이터셋이 동일한 경우, 머신러닝 학습결과도 항상 동일\n",
    "- 2) **None** : 모델 내부에서 랜덤 시드값을 임의로 선택하기 때문에, 결과적으로 파라미터 초기화나 데이터셋 구성 양상이 달라져서 모델과 데이터셋이 동일하더라고 머신러닝 학습결과는 학습할 때마다 달라진다.  \n",
    "  \n",
    "모델을 돌릴 때마다 랜덤적 요소의 변화로 생기는 불확실성 제거 -> 특정 값 고정  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 인스턴스 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# random_state는 모델초기화나 데이터셋 구성에 사용되는 랜덤 시드값입니다. \n",
    "#random_state=None    # 이게 초기값입니다. 아무것도 지정하지 않고 None을 넘겨주면 모델 내부에서 임의로 선택합니다.  \n",
    "random_state=2020        # 하지만 우리는 이렇게 고정값을 세팅해 두겠습니다. \n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest] # 모델 인스턴스 생성 후 models 리스트에 넣어줌\n",
    "\n",
    "print('모델 인스턴스 생성 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GradientBoostingRegressor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 모델의 이름은 클래스의 '__name__' 속성으로 얻을 수 있음\n",
    "gboost.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4가지 모델에 대한 RMSE 값 빠르게 얻을 수 있다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GradientBoostingRegressor': 128360.19649691365,\n",
       " 'XGBRegressor': 110318.66956616656,\n",
       " 'LGBMRegressor': 111920.36735892233,\n",
       " 'RandomForestRegressor': 125487.07102453562}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위를 이용하여 for문 안에서 각 모델 별로 학습 및 예측 가능\n",
    "df = {}\n",
    "\n",
    "for model in models:\n",
    "    # 모델 이름 획득\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    # train, test 데이터셋 분리 - 여기에도 random_state를 고정합니다. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 예측 결과의 rmse값 저장\n",
    "    df[model_name] = rmse(y_test, y_pred)\n",
    "    \n",
    "    # data frame에 저장\n",
    "    score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "    \n",
    "print(\"4가지 모델에 대한 RMSE 값 빠르게 얻을 수 있다.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>128360.196497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>125487.071025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>111920.367359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>110318.669566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    RMSE\n",
       "GradientBoostingRegressor  128360.196497\n",
       "RandomForestRegressor      125487.071025\n",
       "LGBMRegressor              111920.367359\n",
       "XGBRegressor               110318.669566"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_scores(models, train, y):\n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__  # 모델 이름 받아오기\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train,y, random_state = 2020, test_size = 0.2)\n",
    "        model.fit(X_train,y_train) # 모델 학습\n",
    "        y_pred = model.predict(X_test) # 모델 예측\n",
    "        \n",
    "        df[model_name] = rmse(y_test,y_pred)  # 예측값을 rmse로 딕셔너리 저장\n",
    "        score_df = pd.DataFrame(df,index = ['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "        # data frame으로 저장\n",
    "    return score_df\n",
    "\n",
    "get_scores(models, train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 - 그리드 탐색 \n",
    "- **Grid Search** : 격자를 정해놓고 탐색하는 방법 / 사람이 먼저 탐색할 하이퍼 파라미터의 값들을 정해두면, 그 값들로 만들어질 수 있는 모든 조합을 탐색  \n",
    "\n",
    "      \n",
    "    - param_grid : 탐색할 파라미터의 종류 (딕셔너리로 입력)\n",
    "    - scoring : 모델의 성능을 평가할 지표\n",
    "    - cv : cross validation을 수행하기 위해 train 데이터셋을 나누는 조각의 개수\n",
    "    - verbose : 그리드 탐색을 진행하면서 진행 과정을 출력해서 보여줄 메세지의 양 (숫자가 클수록 더 많은 메세지를 출력합니다.)\n",
    "    - n_jobs : 그리드 탐색을 진행하면서 사용할 CPU의 개수\n",
    "\n",
    "- **Random Search** : 사람이 하이퍼 파라미터 공간만 정해두면, 그 안에서 랜덤으로 조합을 탐색함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.model_selection 라이브러리 안에 있는 GridSearchCV 클래스를 활용\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid에 탐색할 xgboost관련 하이퍼 파라미터 넣어서 준비\n",
    "param_grid = {\n",
    "    'num_leaves' : [31],\n",
    "    'n_estimators': [50, 100,150,200],\n",
    "    'max_depth': [10,20,30,40],\n",
    "    'learning_rate' : [0.005],\n",
    "    'feature_fraction' : [0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# 모델 준비 : LightGBM(lgbm) 사용\n",
    "model = LGBMRegressor(random_state=random_state)\n",
    "\n",
    "print('모델 준비 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  80 out of  80 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMRegressor(random_state=2020), n_jobs=5,\n",
       "             param_grid={'feature_fraction': [0.5], 'learning_rate': [0.005],\n",
       "                         'max_depth': [10, 20, 30, 40],\n",
       "                         'n_estimators': [50, 100, 150, 200],\n",
       "                         'num_leaves': [31]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "grid_model.fit(train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "위에서 우리가 입력한 param_grid에 n_estimators 두 가지, max_depth 두 가지를 넣었으므로 가능한 조합은 총 2 × 2 = 4가지입니다.     \n",
    "\n",
    "또한, cross validation은 각 경우마다 5번을 진행하니 총 20 fits를 진행하게 됩니다.\n",
    "\n",
    "여기에서 cross validation을 5번 진행하는 이유는, 각 조합에 대해 단 한 번만 실험을 하는 것보다 5번을 진행해서 평균을 취하는 것이 일반화 오차를 추정하는 데에 더 신뢰도가 높기 때문입니다. 간단하게, 한 번만 해 보는 것보다는 다섯 번을 해보고 구한 평균값이 더 정확하겠죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.11564236, 0.1891746 , 0.25791264, 0.33278604, 0.10549407,\n",
       "        0.18600125, 0.2637629 , 0.33768706, 0.10804415, 0.19470448,\n",
       "        0.26375847, 0.33904004, 0.10899982, 0.18990889, 0.25414462,\n",
       "        0.29249282]),\n",
       " 'std_fit_time': array([0.00531565, 0.00772651, 0.00753965, 0.00660043, 0.00329538,\n",
       "        0.00132769, 0.00929734, 0.01271431, 0.00604125, 0.01090066,\n",
       "        0.00682137, 0.00607263, 0.01044474, 0.00475019, 0.01328401,\n",
       "        0.03800999]),\n",
       " 'mean_score_time': array([0.00839987, 0.01365938, 0.01923933, 0.02648005, 0.00779257,\n",
       "        0.01320109, 0.0202745 , 0.02647638, 0.00799365, 0.01438127,\n",
       "        0.02057047, 0.02651038, 0.00799265, 0.01353335, 0.01980891,\n",
       "        0.02333436]),\n",
       " 'std_score_time': array([0.00076316, 0.00074791, 0.00112904, 0.0005671 , 0.00061345,\n",
       "        0.00096837, 0.00113494, 0.00049005, 0.00027028, 0.00119503,\n",
       "        0.00101029, 0.00095998, 0.00037378, 0.00071497, 0.00050419,\n",
       "        0.00201168]),\n",
       " 'param_feature_fraction': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
       "                    0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 20, 20, 20, 20, 30, 30, 30, 30, 40, 40,\n",
       "                    40, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 50, 100, 150, 200, 50, 100, 150,\n",
       "                    200, 50, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_num_leaves': masked_array(data=[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31,\n",
       "                    31, 31],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 50,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 150,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 10,\n",
       "   'n_estimators': 200,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 20,\n",
       "   'n_estimators': 50,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 20,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 20,\n",
       "   'n_estimators': 150,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 20,\n",
       "   'n_estimators': 200,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 30,\n",
       "   'n_estimators': 50,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 30,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 30,\n",
       "   'n_estimators': 150,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 30,\n",
       "   'n_estimators': 200,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 40,\n",
       "   'n_estimators': 50,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 40,\n",
       "   'n_estimators': 100,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 40,\n",
       "   'n_estimators': 150,\n",
       "   'num_leaves': 31},\n",
       "  {'feature_fraction': 0.5,\n",
       "   'learning_rate': 0.005,\n",
       "   'max_depth': 40,\n",
       "   'n_estimators': 200,\n",
       "   'num_leaves': 31}],\n",
       " 'split0_test_score': array([-0.20805898, -0.15324332, -0.11758069, -0.09277977, -0.20806104,\n",
       "        -0.15324258, -0.11755895, -0.09278812, -0.20806104, -0.15324258,\n",
       "        -0.11755895, -0.09278812, -0.20806104, -0.15324258, -0.11755895,\n",
       "        -0.09278812]),\n",
       " 'split1_test_score': array([-0.20190766, -0.14994297, -0.11615732, -0.0926178 , -0.20190856,\n",
       "        -0.14992775, -0.11614322, -0.09265588, -0.20190856, -0.14992775,\n",
       "        -0.11614322, -0.09265588, -0.20190856, -0.14992775, -0.11614322,\n",
       "        -0.09265588]),\n",
       " 'split2_test_score': array([-0.19738523, -0.14645034, -0.11338528, -0.09030387, -0.19738312,\n",
       "        -0.14641804, -0.11336842, -0.09028998, -0.19738312, -0.14641804,\n",
       "        -0.11336842, -0.09028998, -0.19738312, -0.14641804, -0.11336842,\n",
       "        -0.09028998]),\n",
       " 'split3_test_score': array([-0.20481538, -0.15145946, -0.11685029, -0.09257092, -0.20480744,\n",
       "        -0.15147279, -0.11682994, -0.09257231, -0.20480744, -0.15147279,\n",
       "        -0.11682994, -0.09257231, -0.20480744, -0.15147279, -0.11682994,\n",
       "        -0.09257231]),\n",
       " 'split4_test_score': array([-0.18801337, -0.13761915, -0.10584855, -0.08372877, -0.18802127,\n",
       "        -0.1376821 , -0.10585444, -0.08375901, -0.18802127, -0.1376821 ,\n",
       "        -0.10585444, -0.08375901, -0.18802127, -0.1376821 , -0.10585444,\n",
       "        -0.08375901]),\n",
       " 'mean_test_score': array([-0.20003612, -0.14774305, -0.11396442, -0.09040023, -0.20003629,\n",
       "        -0.14774865, -0.11395099, -0.09041306, -0.20003629, -0.14774865,\n",
       "        -0.11395099, -0.09041306, -0.20003629, -0.14774865, -0.11395099,\n",
       "        -0.09041306]),\n",
       " 'std_test_score': array([0.00696109, 0.00553297, 0.00429924, 0.00345859, 0.00695796,\n",
       "        0.00551193, 0.00428964, 0.00345326, 0.00695796, 0.00551193,\n",
       "        0.00428964, 0.00345326, 0.00695796, 0.00551193, 0.00428964,\n",
       "        0.00345326]),\n",
       " 'rank_test_score': array([13,  9,  8,  1, 14, 10,  5,  2, 14, 10,  5,  2, 14, 10,  5,  2],\n",
       "       dtype=int32)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_model.fit함수를 통해 4가지 조합에 대한 실험 완료 \n",
    "\n",
    "grid_model.cv_results_    # 이 안에 모두 저장 되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 10,\n",
       "  'n_estimators': 50,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 10,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 10,\n",
       "  'n_estimators': 150,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 10,\n",
       "  'n_estimators': 200,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 20,\n",
       "  'n_estimators': 50,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 20,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 20,\n",
       "  'n_estimators': 150,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 20,\n",
       "  'n_estimators': 200,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 30,\n",
       "  'n_estimators': 50,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 30,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 30,\n",
       "  'n_estimators': 150,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 30,\n",
       "  'n_estimators': 200,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 40,\n",
       "  'n_estimators': 50,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 40,\n",
       "  'n_estimators': 100,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 40,\n",
       "  'n_estimators': 150,\n",
       "  'num_leaves': 31},\n",
       " {'feature_fraction': 0.5,\n",
       "  'learning_rate': 0.005,\n",
       "  'max_depth': 40,\n",
       "  'n_estimators': 200,\n",
       "  'num_leaves': 31}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 무슨말이야? 원하는 값만 정제해서 보자 - 어떤 파라미터 조합일 때 점수가 어떻게 나오는가\n",
    "params = grid_model.cv_results_['params']   # 파라미터 조합 params에 저장되어있음\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20003612, -0.14774305, -0.11396442, -0.09040023, -0.20003629,\n",
       "       -0.14774865, -0.11395099, -0.09041306, -0.20003629, -0.14774865,\n",
       "       -0.11395099, -0.09041306, -0.20003629, -0.14774865, -0.11395099,\n",
       "       -0.09041306])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = grid_model.cv_results_['mean_test_score']  # 각각에 대한 테스트 점수는 mean_test_score에 저장되어있음\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적의 성능을 내는 하이퍼 파라미터 조합 찾기\n",
    "- params : 각 파라미터 조합\n",
    "- score : 각 조합에 대한 점수\n",
    "    - 왜 음수일까? :MSE에 음수를 취한 값인 neg_mean_squared_error를 입력했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction  learning_rate  max_depth  n_estimators  num_leaves  \\\n",
       "0                0.5          0.005         10            50          31   \n",
       "1                0.5          0.005         10           100          31   \n",
       "2                0.5          0.005         10           150          31   \n",
       "3                0.5          0.005         10           200          31   \n",
       "4                0.5          0.005         20            50          31   \n",
       "5                0.5          0.005         20           100          31   \n",
       "6                0.5          0.005         20           150          31   \n",
       "7                0.5          0.005         20           200          31   \n",
       "8                0.5          0.005         30            50          31   \n",
       "9                0.5          0.005         30           100          31   \n",
       "10               0.5          0.005         30           150          31   \n",
       "11               0.5          0.005         30           200          31   \n",
       "12               0.5          0.005         40            50          31   \n",
       "13               0.5          0.005         40           100          31   \n",
       "14               0.5          0.005         40           150          31   \n",
       "15               0.5          0.005         40           200          31   \n",
       "\n",
       "       score  \n",
       "0  -0.200036  \n",
       "1  -0.147743  \n",
       "2  -0.113964  \n",
       "3  -0.090400  \n",
       "4  -0.200036  \n",
       "5  -0.147749  \n",
       "6  -0.113951  \n",
       "7  -0.090413  \n",
       "8  -0.200036  \n",
       "9  -0.147749  \n",
       "10 -0.113951  \n",
       "11 -0.090413  \n",
       "12 -0.200036  \n",
       "13 -0.147749  \n",
       "14 -0.113951  \n",
       "15 -0.090413  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(params)\n",
    "results['score'] = score\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147743</td>\n",
       "      <td>0.384374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113964</td>\n",
       "      <td>0.337586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>0.300666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction  learning_rate  max_depth  n_estimators  num_leaves  \\\n",
       "0                0.5          0.005         10            50          31   \n",
       "1                0.5          0.005         10           100          31   \n",
       "2                0.5          0.005         10           150          31   \n",
       "3                0.5          0.005         10           200          31   \n",
       "4                0.5          0.005         20            50          31   \n",
       "5                0.5          0.005         20           100          31   \n",
       "6                0.5          0.005         20           150          31   \n",
       "7                0.5          0.005         20           200          31   \n",
       "8                0.5          0.005         30            50          31   \n",
       "9                0.5          0.005         30           100          31   \n",
       "10               0.5          0.005         30           150          31   \n",
       "11               0.5          0.005         30           200          31   \n",
       "12               0.5          0.005         40            50          31   \n",
       "13               0.5          0.005         40           100          31   \n",
       "14               0.5          0.005         40           150          31   \n",
       "15               0.5          0.005         40           200          31   \n",
       "\n",
       "       score      RMSE  \n",
       "0  -0.200036  0.447254  \n",
       "1  -0.147743  0.384374  \n",
       "2  -0.113964  0.337586  \n",
       "3  -0.090400  0.300666  \n",
       "4  -0.200036  0.447254  \n",
       "5  -0.147749  0.384381  \n",
       "6  -0.113951  0.337566  \n",
       "7  -0.090413  0.300688  \n",
       "8  -0.200036  0.447254  \n",
       "9  -0.147749  0.384381  \n",
       "10 -0.113951  0.337566  \n",
       "11 -0.090413  0.300688  \n",
       "12 -0.200036  0.447254  \n",
       "13 -0.147749  0.384381  \n",
       "14 -0.113951  0.337566  \n",
       "15 -0.090413  0.300688  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 음수 MSE * -1 해주고 np.sqrt로 루트연산 \n",
    "results['RMSE'] = np.sqrt(-1 * results['score'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 본 RMSE 값과 크기가 아주 다르다.  \n",
    "- 원래 price 분포는 한쪽으로 치우쳐져 있음 -> log변환 해주고 -> rmse 값 계산을 위해 np.expm1 함수 활용해 원래대로 복원 -> RMSE 값 계산  \n",
    "  \n",
    "- 그리드 탐색 (np.expm 변환 과정이 없었음) : log변환 되어있는 price 데이터에서 손실함수값 계산함\n",
    "    - RMSLE (Root Mean Squared Log Error) : log를 취한 값에서 RMSE 구함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147743</td>\n",
       "      <td>0.384374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113964</td>\n",
       "      <td>0.337586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>0.300666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction  learning_rate  max_depth  n_estimators  num_leaves  \\\n",
       "0                0.5          0.005         10            50          31   \n",
       "1                0.5          0.005         10           100          31   \n",
       "2                0.5          0.005         10           150          31   \n",
       "3                0.5          0.005         10           200          31   \n",
       "4                0.5          0.005         20            50          31   \n",
       "5                0.5          0.005         20           100          31   \n",
       "6                0.5          0.005         20           150          31   \n",
       "7                0.5          0.005         20           200          31   \n",
       "8                0.5          0.005         30            50          31   \n",
       "9                0.5          0.005         30           100          31   \n",
       "10               0.5          0.005         30           150          31   \n",
       "11               0.5          0.005         30           200          31   \n",
       "12               0.5          0.005         40            50          31   \n",
       "13               0.5          0.005         40           100          31   \n",
       "14               0.5          0.005         40           150          31   \n",
       "15               0.5          0.005         40           200          31   \n",
       "\n",
       "       score     RMSLE  \n",
       "0  -0.200036  0.447254  \n",
       "1  -0.147743  0.384374  \n",
       "2  -0.113964  0.337586  \n",
       "3  -0.090400  0.300666  \n",
       "4  -0.200036  0.447254  \n",
       "5  -0.147749  0.384381  \n",
       "6  -0.113951  0.337566  \n",
       "7  -0.090413  0.300688  \n",
       "8  -0.200036  0.447254  \n",
       "9  -0.147749  0.384381  \n",
       "10 -0.113951  0.337566  \n",
       "11 -0.090413  0.300688  \n",
       "12 -0.200036  0.447254  \n",
       "13 -0.147749  0.384381  \n",
       "14 -0.113951  0.337566  \n",
       "15 -0.090413  0.300688  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼이름 변경 (RMSLE) \n",
    "results = results.rename(columns={'RMSE': 'RMSLE'}) # 컬럼의 이름 변환 - rename\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>0.300666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.090413</td>\n",
       "      <td>0.300688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113951</td>\n",
       "      <td>0.337566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.113964</td>\n",
       "      <td>0.337586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147743</td>\n",
       "      <td>0.384374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.147749</td>\n",
       "      <td>0.384381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.200036</td>\n",
       "      <td>0.447254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction  learning_rate  max_depth  n_estimators  num_leaves  \\\n",
       "3                0.5          0.005         10           200          31   \n",
       "7                0.5          0.005         20           200          31   \n",
       "11               0.5          0.005         30           200          31   \n",
       "15               0.5          0.005         40           200          31   \n",
       "6                0.5          0.005         20           150          31   \n",
       "10               0.5          0.005         30           150          31   \n",
       "14               0.5          0.005         40           150          31   \n",
       "2                0.5          0.005         10           150          31   \n",
       "1                0.5          0.005         10           100          31   \n",
       "5                0.5          0.005         20           100          31   \n",
       "9                0.5          0.005         30           100          31   \n",
       "13               0.5          0.005         40           100          31   \n",
       "0                0.5          0.005         10            50          31   \n",
       "4                0.5          0.005         20            50          31   \n",
       "8                0.5          0.005         30            50          31   \n",
       "12               0.5          0.005         40            50          31   \n",
       "\n",
       "       score     RMSLE  \n",
       "3  -0.090400  0.300666  \n",
       "7  -0.090413  0.300688  \n",
       "11 -0.090413  0.300688  \n",
       "15 -0.090413  0.300688  \n",
       "6  -0.113951  0.337566  \n",
       "10 -0.113951  0.337566  \n",
       "14 -0.113951  0.337566  \n",
       "2  -0.113964  0.337586  \n",
       "1  -0.147743  0.384374  \n",
       "5  -0.147749  0.384381  \n",
       "9  -0.147749  0.384381  \n",
       "13 -0.147749  0.384381  \n",
       "0  -0.200036  0.447254  \n",
       "4  -0.200036  0.447254  \n",
       "8  -0.200036  0.447254  \n",
       "12 -0.200036  0.447254  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSLE 낮은 순서대로 정렬\n",
    "results = results.sort_values('RMSLE')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 조합해서 만들어보기!\n",
    "\"\"\"\n",
    "다음과 같은 과정을 진행할 수 있는 `my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)` 함수를 구현해 보세요.\n",
    "\n",
    "1. GridSearchCV 모델로 `model`을 초기화합니다.\n",
    "2. 모델을 fitting 합니다.\n",
    "3. params, score에 각 조합에 대한 결과를 저장합니다. \n",
    "4. 데이터 프레임을 생성하고, RMSLE 값을 추가한 후 점수가 높은 순서로 정렬한 `results`를 반환합니다.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):     #(1)\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, \\\n",
    "                        scoring='neg_mean_squared_error', \\\n",
    "                        cv=5, verbose=1, n_jobs=5)\n",
    "\n",
    "    grid_model.fit(train, y)     # (2)\n",
    "    \n",
    "    # 어떤 파라미터 조합일 때 점수가 어떻게 나오는가 (3)\n",
    "    params = grid_model.cv_results_['params']   # 파라미터 조합 params에 저장되어있음\n",
    "\n",
    "    score = grid_model.cv_results_['mean_test_score']  # 각각에 대한 테스트 점수는 mean_test_score에 저장되어있음\n",
    "\n",
    "    # (4)\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "\n",
    "    # 음수 MSE * -1 해주고 np.sqrt로 루트연산 \n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    \n",
    "    # RMSLE 낮은 순서대로 정렬\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=5)]: Done  60 out of  60 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025486</td>\n",
       "      <td>0.159642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>800</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025494</td>\n",
       "      <td>0.159667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "      <td>800</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025494</td>\n",
       "      <td>0.159667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025508</td>\n",
       "      <td>0.159713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>800</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025512</td>\n",
       "      <td>0.159725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>600</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025518</td>\n",
       "      <td>0.159745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>600</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025518</td>\n",
       "      <td>0.159745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "      <td>600</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025518</td>\n",
       "      <td>0.159745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025528</td>\n",
       "      <td>0.159776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>600</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025531</td>\n",
       "      <td>0.159785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025551</td>\n",
       "      <td>0.159846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>40</td>\n",
       "      <td>1000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.025551</td>\n",
       "      <td>0.159846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction  learning_rate  max_depth  n_estimators  num_leaves  \\\n",
       "4                0.5           0.05         20           800          31   \n",
       "7                0.5           0.05         30           800          31   \n",
       "10               0.5           0.05         40           800          31   \n",
       "5                0.5           0.05         20          1000          31   \n",
       "1                0.5           0.05         10           800          31   \n",
       "3                0.5           0.05         20           600          31   \n",
       "6                0.5           0.05         30           600          31   \n",
       "9                0.5           0.05         40           600          31   \n",
       "2                0.5           0.05         10          1000          31   \n",
       "0                0.5           0.05         10           600          31   \n",
       "8                0.5           0.05         30          1000          31   \n",
       "11               0.5           0.05         40          1000          31   \n",
       "\n",
       "       score     RMSLE  \n",
       "4  -0.025486  0.159642  \n",
       "7  -0.025494  0.159667  \n",
       "10 -0.025494  0.159667  \n",
       "5  -0.025508  0.159713  \n",
       "1  -0.025512  0.159725  \n",
       "3  -0.025518  0.159745  \n",
       "6  -0.025518  0.159745  \n",
       "9  -0.025518  0.159745  \n",
       "2  -0.025528  0.159776  \n",
       "0  -0.025531  0.159785  \n",
       "8  -0.025551  0.159846  \n",
       "11 -0.025551  0.159846  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_GridSearch() 함수를 통해 간단한 그리드 탐색 \n",
    "\n",
    "\n",
    "                \n",
    "param_grid = {\n",
    "    'num_leaves' : [31],\n",
    "    'n_estimators': [600,800,1000],\n",
    "    'max_depth': [10,20,30,40],\n",
    "    'learning_rate' : [0.05],\n",
    "    'feature_fraction' : [0.5]\n",
    "\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)\n",
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가장 좋은 조합으로 모델 학습 -> 예측값 submission.csv 파일로 만들어 제출\n",
    "-  max_depth=10, n_estimators=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.2159175 , 13.09915102, 14.10493206, ..., 13.03701972,\n",
       "       12.6851225 , 13.01784611])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터로 구성 모델 준비 / 학습 후 예측 결과 생성\n",
    "model = LGBMRegressor(feature_fraction = 0.5, learning_rate = 0.05, max_depth=20, n_estimators=800, num_leaves = 31,random_state=random_state)\n",
    "model.fit(train, y)\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 549034.01794515,  488526.4903414 , 1335653.59674081, ...,\n",
       "        459097.34452466,  322906.92367956,  450378.61985425])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과 np.expm1() 적용해서 원래 스케일로 돌리기\n",
    "prediction = np.expm1(prediction)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   price\n",
       "0  15035  100000\n",
       "1  15036  100000\n",
       "2  15037  100000\n",
       "3  15038  100000\n",
       "4  15039  100000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  sample_submission.csv 파일 가져오기\n",
    "data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "\n",
    "submission_path = join(data_dir, 'sample_submission.csv')\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15035</td>\n",
       "      <td>5.490340e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15036</td>\n",
       "      <td>4.885265e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15037</td>\n",
       "      <td>1.335654e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15038</td>\n",
       "      <td>2.972474e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15039</td>\n",
       "      <td>3.175943e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         price\n",
       "0  15035  5.490340e+05\n",
       "1  15036  4.885265e+05\n",
       "2  15037  1.335654e+06\n",
       "3  15038  2.972474e+05\n",
       "4  15039  3.175943e+05"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 예측한 값 덮어씌우기\n",
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aiffel/aiffel/kaggle_kakr_housing/data/submission_lgbm_RMSLE_0.164399.csv\n"
     ]
    }
   ],
   "source": [
    "submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, 'lgbm', '0.164399')\n",
    "submission.to_csv(submission_csv_path, index=False)\n",
    "print(submission_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 정리하기\n",
    "\"\"\"\n",
    "아래의 과정을 수행하는 `save_submission(model, train, y, test, model_name, rmsle)` 함수를 구현해 주세요.\n",
    "1. 모델을 `train`, `y`로 학습시킵니다.\n",
    "2. `test`에 대해 예측합니다.\n",
    "3. 예측값을 `np.expm1`으로 변환하고, `submission_model_name_RMSLE_100000.csv` 형태의 `csv` 파일을 저장합니다.\n",
    "\"\"\"\n",
    "\n",
    "def save_submission(model, train, y, test, model_name, rmsle):\n",
    "\n",
    "    model.fit(train, y)\n",
    "    \n",
    "    prediction = model.predict(test)\n",
    "    \n",
    "    prediction = np.expm1(prediction)\n",
    "    \n",
    "    \n",
    "    data_dir = os.getenv('HOME')+'/aiffel/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    \n",
    "    # 모델이 예측한 값 덮어씌우기\n",
    "    submission['price'] = prediction\n",
    "    \n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_100000.csv'.format(data_dir, model_name)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    \n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "/home/aiffel/aiffel/kaggle_kakr_housing/data/submission_lgbm_RMSLE_100000.csv saved!\n"
     ]
    }
   ],
   "source": [
    "save_submission(model, train, y, test, 'lgbm', rmsle='0.0168')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 루브릭 평가 요구사항  \n",
    "  \n",
    "### 1) 캐글 데이터분석 전과정이 성공적으로 진행되었는가 ?\n",
    "- 데이터 전처리 후 모델 학습하여 캐글의 submission까지 진행되었다.  \n",
    "\n",
    "### 2) 전처리, 학습과정 및 결과에 대한 설명이 시각화를 포함하여 체계적으로 진행되었는가? ?  \n",
    "- 전처리, 모델 학습, 최적화를 통해 제출 파일을 캐글 커널로 사용 할 수 있도록 만들었다.\n",
    "  \n",
    "    \n",
    "### 3) 회귀모델 예측정확도가 기준 이상 높게 나왔는가 ?  \n",
    "-  하이퍼 파라미터 튜닝 부족으로 Private score가 109371로 나왔다. \n"
   ]
  },
  {
   "attachments": {
    "kaggle1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kaggle1.png](attachment:kaggle1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "처음 캐글 노드를 접했을 때, 노드를 따라가는 것만은 이해가 순조로웠다. 하지만 해커톤 캐글 대회를 통해 내가 알던 정보는 진짜 내가 아는 것이 아니고 이해를 못했다고 느꼈다. 실제로 공부한 내용을 응용하지도 못하는 나에게 너무 속상했다. 3일동안 캐글 코드만 공부하고 다른 분들의 노트북을 분석해보니 조금씩 눈에 보이고 그림이 그려졌다. 이후 캐글 이 프로젝트 제출을 위해 진행할 때, 더 순조롭게 코드가 읽혀져서 다시 흥미를 찾게 되었다. 처음 프로젝트를 진행할 때, Score 낮추는 것에 너무 지쳐 포기하고 제출하려 하였다. 조원분들의 도움으로 파라미터를 조금씩 수정해보니 최종 110000 이하의 Private Score 가 나타났다. 함께 공부하고 도움을 받을 수 있어 포기하지 않고 계속 나아갈 수 있는것 같아 든든하다^__^.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
