{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스기사 요약해보기\n",
    "## 1) 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "import nltk  # 불용어 제거\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup # 데이터 전처리\n",
    "\n",
    "import numpy as np # 텍스트 정제후 빈 샘플 확인\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # 토크나이저\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87801</th>\n",
       "      <td>Mumbai-Goa Tejas Express fully booked for one ...</td>\n",
       "      <td>Indian Railways' Mumbai-Goa luxury train Tejas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40173</th>\n",
       "      <td>Ex-Taliban hostage arrested over sexual assaul...</td>\n",
       "      <td>A Canadian former Taliban hostage, who was arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>If renaming cities helps then all Indians can ...</td>\n",
       "      <td>After some cities were renamed or demanded to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>Sindhu, Verma qualify for BWF Tour Finals' sem...</td>\n",
       "      <td>Indian shuttlers PV Sindhu and Sameer Verma pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86473</th>\n",
       "      <td>Trailer of Johnny Depp's Murder on the Orient ...</td>\n",
       "      <td>The trailer of 'Murder on the Orient Express',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29287</th>\n",
       "      <td>Tesla denies the company exaggerated Model 3 p...</td>\n",
       "      <td>Denying the claims that it exaggerated its abi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28818</th>\n",
       "      <td>Attempted assassination of Zimbabwe Prez caugh...</td>\n",
       "      <td>A video of an attempt to assassinate Zimbabwea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87822</th>\n",
       "      <td>Indian badminton team stuns Indonesia 4-1 in S...</td>\n",
       "      <td>The Indian badminton squad defeated former cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40371</th>\n",
       "      <td>60 booked, 2 detained in protest against Shiml...</td>\n",
       "      <td>Shimla Police on Thursday detained two people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31855</th>\n",
       "      <td>Happy today everyone knows me as Alia's mother...</td>\n",
       "      <td>Actress Soni Razdan has said that she is happy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "87801  Mumbai-Goa Tejas Express fully booked for one ...   \n",
       "40173  Ex-Taliban hostage arrested over sexual assaul...   \n",
       "9936   If renaming cities helps then all Indians can ...   \n",
       "6185   Sindhu, Verma qualify for BWF Tour Finals' sem...   \n",
       "86473  Trailer of Johnny Depp's Murder on the Orient ...   \n",
       "29287  Tesla denies the company exaggerated Model 3 p...   \n",
       "28818  Attempted assassination of Zimbabwe Prez caugh...   \n",
       "87822  Indian badminton team stuns Indonesia 4-1 in S...   \n",
       "40371  60 booked, 2 detained in protest against Shiml...   \n",
       "31855  Happy today everyone knows me as Alia's mother...   \n",
       "\n",
       "                                                    text  \n",
       "87801  Indian Railways' Mumbai-Goa luxury train Tejas...  \n",
       "40173  A Canadian former Taliban hostage, who was arr...  \n",
       "9936   After some cities were renamed or demanded to ...  \n",
       "6185   Indian shuttlers PV Sindhu and Sameer Verma pr...  \n",
       "86473  The trailer of 'Murder on the Orient Express',...  \n",
       "29287  Denying the claims that it exaggerated its abi...  \n",
       "28818  A video of an attempt to assassinate Zimbabwea...  \n",
       "87822  The Indian badminton squad defeated former cha...  \n",
       "40371  Shimla Police on Thursday detained two people ...  \n",
       "31855  Actress Soni Razdan has said that she is happy...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 살펴보기\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추상적 요약 : text를 본문 , headlines를 이미 요약된 데이터로 이용하여 모델학습\n",
    "- 추출적 요약 : text열만 이용  \n",
    "  \n",
    "    \n",
    "## 2) 데이터 전처리 (추상적 요약)\n",
    "- 중복데이터 제거 : drop_duplicates\n",
    "- null 데이터 제거 : .isnull().sum()    /없음\n",
    "- 텍스트 정규화 \n",
    "- 불용어 제거 \n",
    "- **데이터 전처리**  \n",
    "  \n",
    "    \n",
    "- 훈련데이터 / 테스트 데이터 나누기\n",
    "    - 샘플 데이터 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "중복 제거 후 전체 샘플 수 :  98360\n"
     ]
    }
   ],
   "source": [
    "# 중복 샘플 유무 확인 - nunique()\n",
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "\n",
    "# 중복 샘플 제거 - drop_duplicates()\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)     ## drop_duplicates 공부하기\n",
    "print('중복 제거 후 전체 샘플 수 : ', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터에 Null값 남아있을듯 확인해보자 - .isnull().sum()\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 확인\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# # 전처리 전/후 결과 확인\n",
    "# temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "# temp_headlines = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "# print(preprocess_sentence(temp_text))\n",
    "# print(preprocess_sentence(temp_headlines, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years',\n",
       " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "\n",
    "clean_text = []\n",
    "\n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upgrad learner switches to career in ml al with salary hike',\n",
       " 'delhi techie wins free food from swiggy for one year on cred',\n",
       " 'new zealand end rohit sharma led india match winning streak',\n",
       " 'aegon life iterm insurance plan helps customers save tax',\n",
       " 'have known hirani for yrs what if metoo claims are not true sonam']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 Headlines 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "clean_headlines = []\n",
    "\n",
    "for s in data['headlines']:\n",
    "    clean_headlines.append(preprocess_sentence(s, False))  #False = 불용어 제거를 수행하지 않는다.\n",
    "\n",
    "clean_headlines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 정제 후 빈(empty) 값이 생겼는가 ?   -  없네!\n",
    "\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "\n",
    "#.isnull().sum()을 사용해서 Null 값이 생겼는지 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련데이터 / 테스트 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 샘플의 최대 길이 정하기\n",
    "\n",
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 최대길이 / headlines 최대길이 정하기\n",
    "text_max_len = 40\n",
    "headlines_max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9238714924766165\n",
      "전체 샘플 중 길이가 10 이하인 샘플의 비율: 0.8162972753151687\n"
     ]
    }
   ],
   "source": [
    "# Text와 Summary에 적용해서 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 보기\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 74102\n"
     ]
    }
   ],
   "source": [
    "# 정해진 길이보다 길면 제외하는 방식 - 자르는게 아니라\n",
    "\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**시작 토큰 / 종료 토큰 추가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cong wins ramgarh bypoll in rajasthan takes to...</td>\n",
       "      <td>congress candidate shafia zubair ramgarh assem...</td>\n",
       "      <td>sostoken cong wins ramgarh bypoll in rajasthan...</td>\n",
       "      <td>cong wins ramgarh bypoll in rajasthan takes to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>up cousins fed human excreta for friendship wi...</td>\n",
       "      <td>two minor cousins uttar pradesh gorakhpur alle...</td>\n",
       "      <td>sostoken up cousins fed human excreta for frie...</td>\n",
       "      <td>up cousins fed human excreta for friendship wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headlines  \\\n",
       "2   new zealand end rohit sharma led india match w...   \n",
       "3   aegon life iterm insurance plan helps customer...   \n",
       "5   rahat fateh ali khan denies getting notice for...   \n",
       "9   cong wins ramgarh bypoll in rajasthan takes to...   \n",
       "10  up cousins fed human excreta for friendship wi...   \n",
       "\n",
       "                                                 text  \\\n",
       "2   new zealand defeated india wickets fourth odi ...   \n",
       "3   aegon life iterm insurance plan customers enjo...   \n",
       "5   pakistani singer rahat fateh ali khan denied r...   \n",
       "9   congress candidate shafia zubair ramgarh assem...   \n",
       "10  two minor cousins uttar pradesh gorakhpur alle...   \n",
       "\n",
       "                                        decoder_input  \\\n",
       "2   sostoken new zealand end rohit sharma led indi...   \n",
       "3   sostoken aegon life iterm insurance plan helps...   \n",
       "5   sostoken rahat fateh ali khan denies getting n...   \n",
       "9   sostoken cong wins ramgarh bypoll in rajasthan...   \n",
       "10  sostoken up cousins fed human excreta for frie...   \n",
       "\n",
       "                                       decoder_target  \n",
       "2   new zealand end rohit sharma led india match w...  \n",
       "3   aegon life iterm insurance plan helps customer...  \n",
       "5   rahat fateh ali khan denies getting notice for...  \n",
       "9   cong wins ramgarh bypoll in rajasthan takes to...  \n",
       "10  up cousins fed human excreta for friendship wi...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞뒤로 토큰이 잘 붙었다~!\n",
    "# 인코더의 입력, 디코더의 입력, 레이블을 다시 Numpy 타입으로 저장해주기\n",
    "\n",
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66280 23185 67964 ... 49682 28611 18649]\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터/ 테스트 데이터 분리\n",
    "# encoder_input과 크기와 형태가 같은 '순서가 섞인 정수 시퀸스' 만들기\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 시퀸스를 이용해 다시 데이터의 샘플 순서를 정의해주기 = 잘 섞인 샘플\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 14820\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 8:2의 비율로 훈련 데이터 / 테스트 데이터 분리\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)  # 전체 데이터의 크기에서 0.2 곱하기\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 59282\n",
      "훈련 레이블의 개수 : 59282\n",
      "테스트 데이터의 개수 : 14820\n",
      "테스트 레이블의 개수 : 14820\n"
     ]
    }
   ],
   "source": [
    "# 정의된 테스트 데이터의 갯수를 이용해 전체 데이터를 양분\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정수 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문에 해당하는 encoder_input_train 에 대하여 단어 집합 만들기 - 각 단어에 고유한 정수 부여됨\n",
    "# src_tokenizer.word._index에 저장됨\n",
    "\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 61674\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 42366\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 19308\n",
      "단어 집합에서 희귀 단어의 비율: 68.69345267049324\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.204642320936017\n"
     ]
    }
   ],
   "source": [
    "# 등장 빈도수 7회 미만인 단어 비중 확인\n",
    "\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 19000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2055, 228, 15079, 3567, 1216, 1974, 13, 6056, 12124, 433, 1077, 4989, 2388, 2875, 12, 2094, 146, 53, 4335, 4060, 477, 368, 3045, 3268, 1002, 9268, 192, 2094, 146], [12, 916, 122, 2733, 2857, 4869, 639, 233, 2228, 756, 117, 68, 1, 639, 747, 138, 10332, 1124, 2857, 3526, 795, 5829, 10981, 4813, 2857, 4869, 5274, 8446, 4704, 4246, 325, 230, 35, 689, 3006, 4, 155], [125, 137, 483, 1488, 2127, 56, 216, 122, 572, 718, 676, 7254, 5830, 10661, 5, 3161, 1488, 1125, 525, 1343, 41, 2229, 1208, 3379, 2806, 85, 207, 166, 207, 85, 1488, 1467, 215, 78, 996]]\n"
     ]
    }
   ],
   "source": [
    "# texts_to_sequences()는 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩 수행\n",
    "# 정수 인코딩 후 단어 집합의 크기가 19000 넘지 않음\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력 - 정수로 출력되는 모습\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headlines 데이터에 동일 작업 수행\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 27319\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 18286\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9033\n",
      "단어 집합에서 희귀 단어의 비율: 66.93510011347415\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.986653236392839\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 858, 15, 5, 182, 1037, 2249, 303], [1, 425, 999, 3, 71, 2950, 920], [1, 765, 950, 985, 5, 45, 749, 1432, 11, 14, 2418], [1, 1521, 1909, 7497, 1085, 16, 2951, 545, 134], [1, 3139, 3, 1522, 3231, 469, 1250, 5, 131]]\n",
      "target\n",
      "decoder  [[858, 15, 5, 182, 1037, 2249, 303, 2], [425, 999, 3, 71, 2950, 920, 2], [765, 950, 985, 5, 45, 749, 1432, 11, 14, 2418, 2], [1521, 1909, 7497, 1085, 16, 2951, 545, 134, 2], [3139, 3, 1522, 3231, 469, 1250, 5, 131, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 9000 # 단어 집합 크기 제한\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 59281\n",
      "훈련 레이블의 개수 : 59281\n",
      "테스트 데이터의 개수 : 14820\n",
      "테스트 레이블의 개수 : 14820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 낮은 단어일 경우 빈(empty)가 되었을것 \n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128    # 임베딩 차원 128\n",
    "hidden_size = 256      # hideden state 256 : LSTM에서 얼만큼 수용력(capacity)를 가질지 정하는 파라미터\n",
    "                       # LSTM의 용량의 크기, 뉴런의 갯수 - 무조건 용량 크다고 성능 올라가는건 아님\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2432000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1152000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9000)   2313000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,736,104\n",
      "Trainable params: 7,736,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘 (추상적 요약)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수 다운\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 128)      2432000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 40, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 40, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1152000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 40, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 9000)   4617000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,171,432\n",
      "Trainable params: 10,171,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  3/232 [..............................] - ETA: 5:18 - loss: 8.4255"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고 \n",
    "---\n",
    "모델을 자꾸 돌리다 보니, 시간이 너무 오래 걸려서 고생하였다. 특히 마지막에는 gpu가 잡히지 않아 답답하였다. 하지만 이번 프로젝트에서 데이터 전처리 하는 부분을 완벽하게 정리해보려고 노력하였다. 과정을 나열해보고 필요한 부분이 어떤 것인지, 진행하기 위해 필요한 코드와 함수는 어떤 것인지 꼼꼼히 공부하고 정리하였다. 이번주에 블로그에도 정리해서 올릴 예정이다. 완벽히 프로젝트를 끝내지는 못했지만, 전처리 부분이라도 얻고 공부한 느낌이라 약간은 찜찜하지만 뿌듯하다. 다음주 스터디 복습 전까지 끝내는 것이 목표이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
