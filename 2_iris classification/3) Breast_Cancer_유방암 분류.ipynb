{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP 2.3    \n",
    "### Breast_cancer classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"target name은 ['malignant' 'benign'] 입니다.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 import 하기\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 데이터 준비\n",
    "breast_cancer = load_breast_cancer()         \n",
    "\n",
    "\n",
    "breast_cancer_data = breast_cancer.data             #feature data 지정\n",
    "                                                    #breast_cancer_data라는 변수에 breast_cancer의 데이터 입력\n",
    "\n",
    "breast_cancer_label = breast_cancer.target          #label data 지정\n",
    "                                                    #breast_cancer의 label 정보를 변수에 저장\n",
    "\n",
    "print('\"target name은 %s 입니다.\"' %breast_cancer.target_names)            #target names 출력  \n",
    "print(\"\\n\")                                                       #breast_cancer의 종류 알 수 있다 \n",
    "\n",
    "\n",
    "# train, test 데이터 분리 \n",
    "# 모델 학습과 테스트용 문제지와 정답지 준비 \n",
    "X_train, X_test, y_train, y_test = train_test_split (breast_cancer_data,      # 모델의 feature \n",
    "                                                    breast_cancer_label,      # 모델이 맞춰야 하는 정답 (0-9까지의 숫자)\n",
    "                                                    test_size = 0.2,   # 전체 데이터 중 20%를 test데이터로 지정\n",
    "                                                    random_state=32)    # 랜덤으로 train/test data 분리 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target name이 ['malignant' 'benign'] 로 되어 있어 어떤 특징으로 분류 되었는지 알기 어렵다.\n",
    "#              ['음성','양성']\n",
    "# 유방암 데이터 분류 특징/기준\n",
    "\n",
    "breast_cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 여러 특징을 통하여 유방암을 2가지(양섬,음성)으로 분류하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1) Decision Tree 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84        44\n",
      "           1       0.90      0.90      0.90        70\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.87      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8771929824561403"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#(5) 모델 학습 - X_train, y_train 활용하여 분류기 모델 만들기 / 성능 체크\n",
    "decision_tree = DecisionTreeClassifier(random_state = 32)\n",
    "decision_tree.fit(X_train,y_train)      # 모델학습 - training dataset에 맞게 패턴 파악 및 예측/학습\n",
    "y_pred= decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#성능평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2) Random Forest 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        44\n",
      "           1       0.96      0.94      0.95        70\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.94      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3) SVM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81        44\n",
      "           1       0.85      0.96      0.90        70\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.88      0.84      0.85       114\n",
      "weighted avg       0.87      0.87      0.86       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4) SGD Classifier 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        44\n",
      "           1       0.89      0.91      0.90        70\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.87      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8771929824561403"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5) Logistic Regression 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        44\n",
      "           1       0.93      0.93      0.93        70\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.91      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "# 오류나서 추가함 \n",
    "logistic_model = LogisticRegression(solver='lbfgs', max_iter=10000).fit(X_train, y_train)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 분석하기 \n",
    "정답(label)의 분포가 40-114로 불균형하다고 판단하여 accuracy 말고 다른 모델로 선택이 필요하다.  \n",
    "여러가지 특징을 통하여 traget class로 분류 되어야하므로, 유방암의 정확한 특징을 놓치지 않고 양성/음성을 판단하는 과정이 필요할 것으로 보인다. \n",
    "양성인데 음성이라고 판단되어 수술 시기를 놓치는 상황이 적어야한다. \n",
    "  \n",
    "  따라서 **Recall 이 중요하다 !!**\n",
    "\n",
    "\n",
    "- 5가지 모델의 Recall 비교 \n",
    "  - Decision Tree   : 0.87  \n",
    "  - Random Forest: 0.94\n",
    "  - SVM : 0.84\n",
    "  - SGD Classifier : 0.87\n",
    "  - Logistic Regression : 0.91  \n",
    "  \n",
    "Recall의 비교를 통하여 **Random Forest** 모델이 0.94로 가장 높게 나왔다.  \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 루브릭 평가 요구사항  \n",
    "  \n",
    "### 1) 3가지 데이터셋의 구성이 합리적으로 진행되었는가?\n",
    "-  .data와 .target을 통해 feature data와 label data를 지정하였으며, .feature_names과 DESCR을 통하여 데이터 분류의 특징이 되는 기준을 알아보았습니다. \n",
    "  \n",
    "### 2) 3가지 데이터셋에 대해 각각 5가지 모델을 성공적으로 적용하였는가?\n",
    "-  각 데이터셋마다 Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression 모델을 학습하고 테스트를 수행하였습니다.  \n",
    "\n",
    "### 3) 3가지 데이터셋에 대해 모델의 평가지표가 적절히 선택되었는가? \n",
    "-  5가지 모델을 수행 후, 분석하여 각 데이터셋에 필요한 평가지표를 선정하고 모델의 성능을 평가하였습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "# 회고  \n",
    "  \n",
    "  처음 모델 평가를 하게 되면 정확도만 중요하다고 생각이 들었다. 하지만 오차행렬을 학습하고 참이 거짓으로, 거짓이 참으로 판단되는 잘못된 경우도 있다는 것을 알아차리게 되었으며 각 상황에 따라 중요하게 평가되는 평가지표가 나타남을 알 수 있었다.  \n",
    "- 음성을 놓치지 말아야 하는 상황일때, 음성이 양성으로 판단되는 것을 막아야하므로 FP가 낮을 수록 좋고 따라서 정밀도(Precision)가 높은 모델을 선택하면 좋다.  \n",
    "\n",
    "- 양성을 놓치지 말아야 하는 상황일때, 양성이 음성으로 판단되는 것을 막아야하므로 FN이 낮을 수록 좋고 따라서 재현율(Recall)이 높은 모델을 선택하면 좋다.  \n",
    "\n",
    "각각 다른 기준을 가진 데이터셋을 여러가지 평가지표로 다양한 방향으로 판단할 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
